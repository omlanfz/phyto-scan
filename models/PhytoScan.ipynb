{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8852a378-a053-494f-8d72-4a48c53178a4",
   "metadata": {},
   "source": [
    "## <center style='color:purple'>PhytoScan: AI-Powered Plant Disease Detection</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854a4a4-8baf-4d0a-9f4e-fcbb032d29d6",
   "metadata": {},
   "source": [
    "Dataset is downloaded from: https://www.kaggle.com/datasets/tushar5harma/plant-village-dataset-updated/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1595044-8d2b-4758-a81e-92bf90447812",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Importing necessary libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fd12d5-db8c-49a6-b17d-2229839aaf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in c:\\users\\user\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!pip install \"numpy<2\"\n",
    "import numpy as np\n",
    "!pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ae4923-7b1a-4529-9582-09a9e8ee23f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f138d7-5554-4857-b97c-dce474b6a0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # This should print the installed TensorFlow version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4b274-d028-44a5-8120-05deb6801af8",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Define dataset path</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20031fe6-e2bd-4f62-8cc9-5d13b3830fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./plant-village-dataset\n"
     ]
    }
   ],
   "source": [
    "# Define dataset path\n",
    "data_dir = \"./plant-village-dataset\" \n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc6e776-e4a2-4c19-9c31-62b7876ffa64",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Image parameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "462b26d9-8560-4067-9f56-4f1e59c57319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1325e58-25bd-4c27-9eaa-c5390a8374da",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Preprocessing Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cfc62bf-cccd-435d-a703-150d9c76a86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "def preprocess_image(image):\n",
    "    img_array = np.array(image) / 255.0  # Normalize first\n",
    "    p2, p98 = np.percentile(img_array, (2, 98))\n",
    "    return exposure.rescale_intensity(img_array, in_range=(p2, p98))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76721064-9a7a-425d-af05-31d3d2d529e6",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Data Augmentation and Loading</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48512e95-9d3e-4bd9-8232-6b80596b8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import exposure\n",
    "\n",
    "# def contrast_stretching(image):\n",
    "#     # Convert image to numpy array\n",
    "#     img_array = np.array(image)\n",
    "#     # Apply contrast stretching\n",
    "#     p2, p98 = np.percentile(img_array, (2, 98))\n",
    "#     img_rescaled = exposure.rescale_intensity(img_array, in_range=(p2, p98))\n",
    "#     return img_rescaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11588d6b-04ad-4e96-a987-5eb8d65b1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation and Loading\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image,\n",
    "    # rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    # brightness_range=[0.8, 1.2],  # Adjust brightness\n",
    "    # contrast_stretching=True,  # Enhance contrast\n",
    "    # preprocessing_function=contrast_stretching,\n",
    "    validation_split=0.2\n",
    ")\n",
    "# Load test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# # Data Augmentation and Loading\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     validation_split=0.2\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9708a6ad-5dd6-410d-aed3-bcb080073c70",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Get all plant species folders</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31bd18fa-eb5c-4995-8d5d-a0f069ac5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all plant species folders\n",
    "plant_species = [folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963761df-eb8c-4c0f-baf5-d7d337e25a61",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Load Data for All Species</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae9d481f-864e-4442-a800-f9695b174e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for: Apple\n",
      "Found 7771 images belonging to 4 classes.\n",
      "Found 1747 images belonging to 4 classes.\n",
      "Found 196 images belonging to 4 classes.\n",
      "Loading data for: Bell Pepper\n",
      "Found 3901 images belonging to 2 classes.\n",
      "Found 877 images belonging to 2 classes.\n",
      "Found 98 images belonging to 2 classes.\n",
      "Loading data for: Cherry\n",
      "Found 3509 images belonging to 2 classes.\n",
      "Found 788 images belonging to 2 classes.\n",
      "Found 89 images belonging to 2 classes.\n",
      "Loading data for: Corn (Maize)\n",
      "Found 7316 images belonging to 4 classes.\n",
      "Found 1645 images belonging to 4 classes.\n",
      "Found 188 images belonging to 4 classes.\n",
      "Loading data for: Grape\n",
      "Found 7222 images belonging to 4 classes.\n",
      "Found 1623 images belonging to 4 classes.\n",
      "Found 182 images belonging to 4 classes.\n",
      "Loading data for: Potato\n",
      "Found 5702 images belonging to 3 classes.\n",
      "Found 1282 images belonging to 3 classes.\n",
      "Found 144 images belonging to 3 classes.\n",
      "Loading data for: Tomato\n",
      "Found 11108 images belonging to 6 classes.\n",
      "Found 2495 images belonging to 6 classes.\n",
      "Found 280 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store data generators per species\n",
    "train_generators = {}\n",
    "val_generators = {}\n",
    "test_generators = {}\n",
    "\n",
    "# Loop through each plant species folder\n",
    "for plant in os.listdir(data_dir):\n",
    "    plant_path = os.path.join(data_dir, plant)\n",
    "    \n",
    "    if not os.path.isdir(plant_path):\n",
    "        continue  # Skip files if any\n",
    "\n",
    "    print(f\"Loading data for: {plant}\")\n",
    "\n",
    "    train_path = os.path.join(plant_path, \"Train\")\n",
    "    val_path = os.path.join(plant_path, \"Val\")\n",
    "    test_path = os.path.join(plant_path, \"Test\")\n",
    "\n",
    "    # Train generator\n",
    "    train_generators[plant] = datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Validation generator\n",
    "    val_generators[plant] = datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Test generator\n",
    "    test_generators[plant] = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6b368-2f06-4b5b-a761-d713ac343fd6",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Load training and validation sets</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0eb414-c458-450f-98bc-cb57fe3e1c1d",
   "metadata": {},
   "source": [
    "# Load training and validation sets\n",
    "train_generators = []\n",
    "val_generators = []\n",
    "\n",
    "for plant in plant_species:\n",
    "    train_path = os.path.join(data_dir, plant, 'Train')\n",
    "    val_path = os.path.join(data_dir, plant, 'Val')\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    print(f\"{plant}: Train - {train_generator.samples} images, {train_generator.num_classes} classes | \"\n",
    "          f\"Validation - {val_generator.samples} images, {val_generator.num_classes} classes\\n\")\n",
    "    \n",
    "    train_generators.append(train_generator)\n",
    "    val_generators.append(val_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b78eb-3891-4bda-be78-c6575cccea0a",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Load test set</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa748ee-320b-4fbc-8e8a-46c29649a599",
   "metadata": {},
   "source": [
    "# Load test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generators = []\n",
    "\n",
    "for plant in plant_species:\n",
    "    test_path = os.path.join(data_dir, plant, 'Test')\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    print(f\"{plant}: Test - {test_generator.samples} images, {test_generator.num_classes} classes\\n\")\n",
    "    test_generators.append(test_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1a54d2-c380-45a5-9893-e2919d297f09",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Define the model using EfficientNet</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c47eb-bace-4975-8599-eb3f0eb6fe27",
   "metadata": {},
   "source": [
    "# Define the model using EfficientNet\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870d7f3-b9d1-4d47-a383-7e70eca64a75",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Freeze most of the model, but leave the last 20 layers trainable</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc7e4f5-163a-4d15-bdfc-afaa5ca5e426",
   "metadata": {},
   "source": [
    "# Freeze most of the model, but leave the last 20 layers trainable\n",
    "for layer in base_model.layers[:-20]:  # Freeze all layers except the last 20\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in base_model.layers[-20:]:  # Unfreeze the last 20 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# # Freeze base model layers\n",
    "# base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c8244-bb17-489c-9cb7-c5f7b9b7012e",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Add custom classification layers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f0416c-df45-4e9f-9727-8eb06f0b3b43",
   "metadata": {},
   "source": [
    "# Add custom classification layers\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output_layer = Dense(train_generator.num_classes, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e45d47-b1a3-4eef-a781-67dc160635e0",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Create the model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9426e529-9b2e-4765-8e43-6d1aa9dfb86e",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4834d8-94a8-462e-8587-4cf82d5a7047",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Compile the model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b48862-302e-4b15-bbe9-f6051448455a",
   "metadata": {},
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac7d35-ecec-4a69-a33d-d01c1a954252",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Train the model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a1c704-bee3-4b8d-8148-7b5e487146a5",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generators[0],\n",
    "    validation_data=val_generators[0],\n",
    "    epochs = 20,\n",
    "    steps_per_epoch=len(train_generators[0]),\n",
    "    validation_steps=len(val_generators[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9870f-550a-4131-b1ab-029e7df6e1a5",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Train Separate Models per Plant</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fbecfe61-c56c-4901-934a-94b2cd405821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for: Apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 2s/step - accuracy: 0.7771 - loss: 0.6164 - val_accuracy: 0.2267 - val_loss: 1.4287\n",
      "Epoch 2/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 2s/step - accuracy: 0.9850 - loss: 0.0430 - val_accuracy: 0.3486 - val_loss: 1.5753\n",
      "Epoch 3/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 2s/step - accuracy: 0.9930 - loss: 0.0208 - val_accuracy: 0.8140 - val_loss: 0.4669\n",
      "Epoch 4/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 2s/step - accuracy: 0.9957 - loss: 0.0157 - val_accuracy: 0.9267 - val_loss: 0.1924\n",
      "Epoch 5/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 2s/step - accuracy: 0.9971 - loss: 0.0123 - val_accuracy: 0.8563 - val_loss: 0.3817\n",
      "Epoch 6/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 2s/step - accuracy: 0.9954 - loss: 0.0141 - val_accuracy: 0.7876 - val_loss: 0.5569\n",
      "Epoch 7/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 2s/step - accuracy: 0.9965 - loss: 0.0122 - val_accuracy: 0.9908 - val_loss: 0.0244\n",
      "Epoch 8/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 2s/step - accuracy: 0.9980 - loss: 0.0054 - val_accuracy: 0.8500 - val_loss: 0.3821\n",
      "Epoch 9/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 2s/step - accuracy: 0.9946 - loss: 0.0161 - val_accuracy: 0.9038 - val_loss: 0.2556\n",
      "Epoch 10/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 2s/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9336 - val_loss: 0.1910\n",
      "Epoch 11/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 2s/step - accuracy: 0.9971 - loss: 0.0072 - val_accuracy: 0.7172 - val_loss: 0.6942\n",
      "Epoch 12/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 2s/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.8226 - val_loss: 0.4782\n",
      "Epoch 13/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 2s/step - accuracy: 0.9977 - loss: 0.0043 - val_accuracy: 0.6451 - val_loss: 1.2339\n",
      "Epoch 14/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 2s/step - accuracy: 0.9979 - loss: 0.0043 - val_accuracy: 0.7813 - val_loss: 1.0594\n",
      "Epoch 15/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 2s/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.2335 - val_loss: 2.4905\n",
      "Epoch 16/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 2s/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.3160 - val_loss: 1.9521\n",
      "Epoch 17/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 2s/step - accuracy: 0.9990 - loss: 0.0021 - val_accuracy: 0.9897 - val_loss: 0.0349\n",
      "Epoch 18/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 2s/step - accuracy: 0.9988 - loss: 0.0030 - val_accuracy: 0.8884 - val_loss: 0.2825\n",
      "Epoch 19/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 2s/step - accuracy: 0.9979 - loss: 0.0050 - val_accuracy: 0.9502 - val_loss: 0.1277\n",
      "Epoch 20/20\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 2s/step - accuracy: 0.9990 - loss: 0.0021 - val_accuracy: 0.9788 - val_loss: 0.0619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for Apple!\n",
      "\n",
      "\n",
      "Training model for: Bell Pepper\n",
      "Epoch 1/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 2s/step - accuracy: 0.8363 - loss: 0.3454 - val_accuracy: 0.5097 - val_loss: 0.6929\n",
      "Epoch 2/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 2s/step - accuracy: 0.9895 - loss: 0.0321 - val_accuracy: 0.5097 - val_loss: 0.8892\n",
      "Epoch 3/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.9960 - loss: 0.0145 - val_accuracy: 0.5291 - val_loss: 1.4060\n",
      "Epoch 4/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 2s/step - accuracy: 0.9950 - loss: 0.0108 - val_accuracy: 0.5120 - val_loss: 1.7512\n",
      "Epoch 5/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.9927 - loss: 0.0173 - val_accuracy: 0.6249 - val_loss: 1.2319\n",
      "Epoch 6/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2s/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.7013 - val_loss: 1.0219\n",
      "Epoch 7/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 2s/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.6465 - val_loss: 1.0709\n",
      "Epoch 8/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 2s/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.5097 - val_loss: 1.6086\n",
      "Epoch 9/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.9986 - loss: 0.0056 - val_accuracy: 0.7127 - val_loss: 0.5226\n",
      "Epoch 10/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 2s/step - accuracy: 0.9975 - loss: 0.0108 - val_accuracy: 0.5097 - val_loss: 1.5628\n",
      "Epoch 11/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 2s/step - accuracy: 0.9999 - loss: 0.0032 - val_accuracy: 0.6146 - val_loss: 1.0517\n",
      "Epoch 12/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 2s/step - accuracy: 0.9967 - loss: 0.0063 - val_accuracy: 0.5485 - val_loss: 0.9284\n",
      "Epoch 13/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 0.9988 - loss: 0.0027 - val_accuracy: 0.9966 - val_loss: 0.0104\n",
      "Epoch 14/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9795 - val_loss: 0.0585\n",
      "Epoch 15/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.2622e-04 - val_accuracy: 0.9989 - val_loss: 0.0030\n",
      "Epoch 16/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - accuracy: 0.9979 - loss: 0.0056 - val_accuracy: 0.6135 - val_loss: 1.4005\n",
      "Epoch 17/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9943 - val_loss: 0.0227\n",
      "Epoch 18/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - accuracy: 0.9967 - loss: 0.0084 - val_accuracy: 0.9977 - val_loss: 0.0097\n",
      "Epoch 19/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.7951e-04 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 20/20\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - accuracy: 0.9999 - loss: 5.6571e-04 - val_accuracy: 0.9818 - val_loss: 0.0475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for Bell Pepper!\n",
      "\n",
      "\n",
      "Training model for: Cherry\n",
      "Epoch 1/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 2s/step - accuracy: 0.8963 - loss: 0.2435 - val_accuracy: 0.4797 - val_loss: 0.7046\n",
      "Epoch 2/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9985 - loss: 0.0072 - val_accuracy: 0.2284 - val_loss: 0.7526\n",
      "Epoch 3/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.4949 - val_loss: 0.7631\n",
      "Epoch 4/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.5076 - val_loss: 0.6885\n",
      "Epoch 5/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9657 - val_loss: 0.1865\n",
      "Epoch 6/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.8325 - val_loss: 0.3591\n",
      "Epoch 7/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9327 - val_loss: 0.1731\n",
      "Epoch 8/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.3133e-04 - val_accuracy: 0.9987 - val_loss: 0.0089\n",
      "Epoch 9/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.5993e-04 - val_accuracy: 1.0000 - val_loss: 3.5057e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.7061e-04 - val_accuracy: 1.0000 - val_loss: 5.8100e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 1.1229e-04 - val_accuracy: 1.0000 - val_loss: 1.1167e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.9860e-05 - val_accuracy: 1.0000 - val_loss: 1.7631e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.1334e-04 - val_accuracy: 1.0000 - val_loss: 8.9268e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.0508e-04 - val_accuracy: 1.0000 - val_loss: 4.5501e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.0612e-04 - val_accuracy: 1.0000 - val_loss: 1.7828e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 2s/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.5495 - val_loss: 0.7912\n",
      "Epoch 17/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.8891e-04 - val_accuracy: 0.6865 - val_loss: 0.4816\n",
      "Epoch 18/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.2091e-04 - val_accuracy: 1.0000 - val_loss: 3.3301e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 8.8298e-05 - val_accuracy: 0.9848 - val_loss: 0.0463\n",
      "Epoch 20/20\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 8.4206e-05 - val_accuracy: 1.0000 - val_loss: 4.3263e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for Cherry!\n",
      "\n",
      "\n",
      "Training model for: Corn (Maize)\n",
      "Epoch 1/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 2s/step - accuracy: 0.8012 - loss: 0.5528 - val_accuracy: 0.1538 - val_loss: 1.5989\n",
      "Epoch 2/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.9692 - loss: 0.0947 - val_accuracy: 0.2705 - val_loss: 1.8758\n",
      "Epoch 3/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 2s/step - accuracy: 0.9773 - loss: 0.0609 - val_accuracy: 0.5155 - val_loss: 1.5015\n",
      "Epoch 4/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 2s/step - accuracy: 0.9802 - loss: 0.0512 - val_accuracy: 0.6979 - val_loss: 0.8148\n",
      "Epoch 5/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 2s/step - accuracy: 0.9857 - loss: 0.0438 - val_accuracy: 0.4286 - val_loss: 1.6963\n",
      "Epoch 6/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 2s/step - accuracy: 0.9894 - loss: 0.0328 - val_accuracy: 0.5915 - val_loss: 1.3412\n",
      "Epoch 7/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.9906 - loss: 0.0283 - val_accuracy: 0.8456 - val_loss: 0.4489\n",
      "Epoch 8/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.9923 - loss: 0.0235 - val_accuracy: 0.8802 - val_loss: 0.3510\n",
      "Epoch 9/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 2s/step - accuracy: 0.9935 - loss: 0.0174 - val_accuracy: 0.8559 - val_loss: 0.3607\n",
      "Epoch 10/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 2s/step - accuracy: 0.9934 - loss: 0.0188 - val_accuracy: 0.5763 - val_loss: 1.3390\n",
      "Epoch 11/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 2s/step - accuracy: 0.9961 - loss: 0.0122 - val_accuracy: 0.6748 - val_loss: 0.8792\n",
      "Epoch 12/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 2s/step - accuracy: 0.9945 - loss: 0.0181 - val_accuracy: 0.5520 - val_loss: 1.9824\n",
      "Epoch 13/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 2s/step - accuracy: 0.9959 - loss: 0.0114 - val_accuracy: 0.7191 - val_loss: 0.7958\n",
      "Epoch 14/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 2s/step - accuracy: 0.9959 - loss: 0.0142 - val_accuracy: 0.9745 - val_loss: 0.0861\n",
      "Epoch 15/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 2s/step - accuracy: 0.9963 - loss: 0.0092 - val_accuracy: 0.6809 - val_loss: 1.0746\n",
      "Epoch 16/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 2s/step - accuracy: 0.9960 - loss: 0.0115 - val_accuracy: 0.2498 - val_loss: 3.4457\n",
      "Epoch 17/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 2s/step - accuracy: 0.9956 - loss: 0.0132 - val_accuracy: 0.9210 - val_loss: 0.2456\n",
      "Epoch 18/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 2s/step - accuracy: 0.9969 - loss: 0.0075 - val_accuracy: 0.2602 - val_loss: 3.8611\n",
      "Epoch 19/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 2s/step - accuracy: 0.9960 - loss: 0.0125 - val_accuracy: 0.4480 - val_loss: 2.2135\n",
      "Epoch 20/20\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 2s/step - accuracy: 0.9968 - loss: 0.0111 - val_accuracy: 0.9021 - val_loss: 0.3093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for Corn (Maize)!\n",
      "\n",
      "\n",
      "Training model for: Grape\n",
      "Epoch 1/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 2s/step - accuracy: 0.7899 - loss: 0.5669 - val_accuracy: 0.2329 - val_loss: 1.3799\n",
      "Epoch 2/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 2s/step - accuracy: 0.9916 - loss: 0.0338 - val_accuracy: 0.6198 - val_loss: 0.9086\n",
      "Epoch 3/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 2s/step - accuracy: 0.9898 - loss: 0.0283 - val_accuracy: 0.9322 - val_loss: 0.1943\n",
      "Epoch 4/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 2s/step - accuracy: 0.9977 - loss: 0.0087 - val_accuracy: 0.9864 - val_loss: 0.0355\n",
      "Epoch 5/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 2s/step - accuracy: 0.9965 - loss: 0.0086 - val_accuracy: 0.7813 - val_loss: 0.5439\n",
      "Epoch 6/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 2s/step - accuracy: 0.9993 - loss: 0.0042 - val_accuracy: 0.8121 - val_loss: 0.4834\n",
      "Epoch 7/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 2s/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 0.6999 - val_loss: 1.1290\n",
      "Epoch 8/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.9989 - loss: 0.0048 - val_accuracy: 0.9932 - val_loss: 0.0243\n",
      "Epoch 9/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.5077 - val_loss: 1.4646\n",
      "Epoch 10/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.6168 - val_loss: 1.5970\n",
      "Epoch 11/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.8854 - val_loss: 0.3193\n",
      "Epoch 12/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 2s/step - accuracy: 0.9980 - loss: 0.0039 - val_accuracy: 0.9581 - val_loss: 0.1276\n",
      "Epoch 13/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 2s/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.2341 - val_loss: 5.7000\n",
      "Epoch 14/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.9982 - loss: 0.0048 - val_accuracy: 0.9600 - val_loss: 0.1032\n",
      "Epoch 15/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 2s/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.6593 - val_loss: 1.0416\n",
      "Epoch 16/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 2s/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.8324 - val_loss: 0.4848\n",
      "Epoch 17/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 2s/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.8885 - val_loss: 0.3094\n",
      "Epoch 18/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 2s/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9877 - val_loss: 0.0361\n",
      "Epoch 19/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 2s/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.8035 - val_loss: 0.6381\n",
      "Epoch 20/20\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 2s/step - accuracy: 0.9989 - loss: 0.0045 - val_accuracy: 0.9920 - val_loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for Grape!\n",
      "\n",
      "\n",
      "Training model for: Potato\n",
      "Epoch 1/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 2s/step - accuracy: 0.8370 - loss: 0.4327 - val_accuracy: 0.3198 - val_loss: 1.0991\n",
      "Epoch 2/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.9943 - loss: 0.0201 - val_accuracy: 0.3237 - val_loss: 1.0881\n",
      "Epoch 3/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.9945 - loss: 0.0157 - val_accuracy: 0.3198 - val_loss: 1.1903\n",
      "Epoch 4/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9963 - loss: 0.0124 - val_accuracy: 0.9774 - val_loss: 0.0576\n",
      "Epoch 5/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9964 - loss: 0.0121 - val_accuracy: 0.8003 - val_loss: 0.4526\n",
      "Epoch 6/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.9446 - val_loss: 0.1496\n",
      "Epoch 7/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.8034 - val_loss: 0.5070\n",
      "Epoch 8/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.9972 - loss: 0.0071 - val_accuracy: 0.9797 - val_loss: 0.0770\n",
      "Epoch 9/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.6123 - val_loss: 0.9573\n",
      "Epoch 10/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 2s/step - accuracy: 0.9980 - loss: 0.0076 - val_accuracy: 0.3619 - val_loss: 2.1799\n",
      "Epoch 11/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 2s/step - accuracy: 0.9976 - loss: 0.0059 - val_accuracy: 0.9930 - val_loss: 0.0257\n",
      "Epoch 12/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9891 - val_loss: 0.0431\n",
      "Epoch 13/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.9181 - val_loss: 0.2187\n",
      "Epoch 14/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.9979 - loss: 0.0053 - val_accuracy: 0.3198 - val_loss: 3.0070\n",
      "Epoch 15/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9964 - loss: 0.0106 - val_accuracy: 0.8931 - val_loss: 0.3330\n",
      "Epoch 16/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9995 - loss: 0.0034 - val_accuracy: 0.9984 - val_loss: 0.0082\n",
      "Epoch 17/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.9986 - loss: 0.0056 - val_accuracy: 0.9665 - val_loss: 0.0917\n",
      "Epoch 18/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9999 - loss: 0.0022 - val_accuracy: 0.9805 - val_loss: 0.0471\n",
      "Epoch 19/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9758 - val_loss: 0.0713\n",
      "Epoch 20/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9990 - loss: 0.0024 - val_accuracy: 0.7309 - val_loss: 0.7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for Potato!\n",
      "\n",
      "\n",
      "Training model for: Tomato\n",
      "Epoch 1/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 2s/step - accuracy: 0.7164 - loss: 0.7965 - val_accuracy: 0.1667 - val_loss: 2.0973\n",
      "Epoch 2/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 2s/step - accuracy: 0.9569 - loss: 0.1141 - val_accuracy: 0.6024 - val_loss: 1.0896\n",
      "Epoch 3/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 2s/step - accuracy: 0.9803 - loss: 0.0602 - val_accuracy: 0.8309 - val_loss: 0.4867\n",
      "Epoch 4/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 2s/step - accuracy: 0.9851 - loss: 0.0436 - val_accuracy: 0.3964 - val_loss: 2.0198\n",
      "Epoch 5/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 2s/step - accuracy: 0.9873 - loss: 0.0351 - val_accuracy: 0.4754 - val_loss: 2.1939\n",
      "Epoch 6/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 2s/step - accuracy: 0.9906 - loss: 0.0317 - val_accuracy: 0.5331 - val_loss: 1.4339\n",
      "Epoch 7/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 2s/step - accuracy: 0.9915 - loss: 0.0275 - val_accuracy: 0.8882 - val_loss: 0.3219\n",
      "Epoch 8/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 2s/step - accuracy: 0.9905 - loss: 0.0279 - val_accuracy: 0.4609 - val_loss: 1.6871\n",
      "Epoch 9/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 2s/step - accuracy: 0.9930 - loss: 0.0184 - val_accuracy: 0.9703 - val_loss: 0.1002\n",
      "Epoch 10/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 2s/step - accuracy: 0.9951 - loss: 0.0159 - val_accuracy: 0.9319 - val_loss: 0.1987\n",
      "Epoch 11/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 2s/step - accuracy: 0.9936 - loss: 0.0217 - val_accuracy: 0.7948 - val_loss: 0.8503\n",
      "Epoch 12/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 2s/step - accuracy: 0.9945 - loss: 0.0162 - val_accuracy: 0.7335 - val_loss: 1.0030\n",
      "Epoch 13/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 2s/step - accuracy: 0.9948 - loss: 0.0169 - val_accuracy: 0.4926 - val_loss: 2.2323\n",
      "Epoch 14/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 2s/step - accuracy: 0.9961 - loss: 0.0136 - val_accuracy: 0.5964 - val_loss: 2.1114\n",
      "Epoch 15/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 2s/step - accuracy: 0.9933 - loss: 0.0225 - val_accuracy: 0.9142 - val_loss: 0.2656\n",
      "Epoch 16/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 2s/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.8878 - val_loss: 0.4535\n",
      "Epoch 17/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 2s/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.7555 - val_loss: 1.1323\n",
      "Epoch 18/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 2s/step - accuracy: 0.9937 - loss: 0.0153 - val_accuracy: 0.5940 - val_loss: 1.8174\n",
      "Epoch 19/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 2s/step - accuracy: 0.9958 - loss: 0.0145 - val_accuracy: 0.4902 - val_loss: 1.7877\n",
      "Epoch 20/20\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 2s/step - accuracy: 0.9969 - loss: 0.0088 - val_accuracy: 0.7130 - val_loss: 1.4259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for Tomato!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for plant in train_generators.keys():\n",
    "    print(f\"\\nTraining model for: {plant}\")\n",
    "\n",
    "    num_classes = train_generators[plant].num_classes\n",
    "\n",
    "    # Load EfficientNet model\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Unfreeze last 20 layers for fine-tuning\n",
    "    for layer in base_model.layers[-20:]:\n",
    "        layer.trainable = True  \n",
    "\n",
    "    # Add custom classification layers\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generators[plant],\n",
    "        validation_data=val_generators[plant],\n",
    "        epochs=20,\n",
    "        steps_per_epoch=len(train_generators[plant]),\n",
    "        validation_steps=len(val_generators[plant])\n",
    "    )\n",
    "\n",
    "    # Save model for each plant\n",
    "    model.save(f\"model_{plant}.h5\")\n",
    "    print(f\"Model saved for {plant}!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f463f00e-3aa2-4256-8b88-b6ad0d3cb00d",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Evaluate each model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ca7364e5-6284-4e7d-936d-31002f4e7248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model for: Apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 297ms/step - accuracy: 0.9655 - loss: 0.0911\n",
      "Test Accuracy for Apple: 0.9541\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 366ms/step\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Apple Scab       0.91      0.98      0.94        51\n",
      "       Black Rot       1.00      1.00      1.00        50\n",
      "Cedar Apple Rust       1.00      0.82      0.90        44\n",
      "         Healthy       0.93      1.00      0.96        51\n",
      "\n",
      "        accuracy                           0.95       196\n",
      "       macro avg       0.96      0.95      0.95       196\n",
      "    weighted avg       0.96      0.95      0.95       196\n",
      "\n",
      "\n",
      "Evaluating model for: Bell Pepper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 0.0076\n",
      "Test Accuracy for Bell Pepper: 1.0000\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017EC2A35DA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017EC2A35DA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 469ms/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Bacterial Spot       1.00      1.00      1.00        48\n",
      "       Healthy       1.00      1.00      1.00        50\n",
      "\n",
      "      accuracy                           1.00        98\n",
      "     macro avg       1.00      1.00      1.00        98\n",
      "  weighted avg       1.00      1.00      1.00        98\n",
      "\n",
      "\n",
      "Evaluating model for: Cherry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 318ms/step - accuracy: 0.9905 - loss: 0.0208\n",
      "Test Accuracy for Cherry: 0.9888\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017EC767DDA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017EC767DDA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642ms/step\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       Healthy       0.98      1.00      0.99        46\n",
      "Powdery Mildew       1.00      0.98      0.99        43\n",
      "\n",
      "      accuracy                           0.99        89\n",
      "     macro avg       0.99      0.99      0.99        89\n",
      "  weighted avg       0.99      0.99      0.99        89\n",
      "\n",
      "\n",
      "Evaluating model for: Corn (Maize)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 344ms/step - accuracy: 0.8368 - loss: 0.7914\n",
      "Test Accuracy for Corn (Maize): 0.8404\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 428ms/step\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Cercospora Leaf Spot       0.70      0.73      0.72        45\n",
      "         Common Rust       1.00      0.94      0.97        48\n",
      "             Healthy       0.77      1.00      0.87        47\n",
      "Northern Leaf Blight       0.94      0.69      0.80        48\n",
      "\n",
      "            accuracy                           0.84       188\n",
      "           macro avg       0.85      0.84      0.84       188\n",
      "        weighted avg       0.86      0.84      0.84       188\n",
      "\n",
      "\n",
      "Evaluating model for: Grape\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 320ms/step - accuracy: 0.9882 - loss: 0.0543\n",
      "Test Accuracy for Grape: 0.9945\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 411ms/step\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           Black Rot       1.00      0.98      0.99        48\n",
      "Esca (Black Measles)       1.00      1.00      1.00        48\n",
      "             Healthy       0.98      1.00      0.99        43\n",
      "         Leaf Blight       1.00      1.00      1.00        43\n",
      "\n",
      "            accuracy                           0.99       182\n",
      "           macro avg       0.99      0.99      0.99       182\n",
      "        weighted avg       0.99      0.99      0.99       182\n",
      "\n",
      "\n",
      "Evaluating model for: Potato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 295ms/step - accuracy: 0.4083 - loss: 1.9498\n",
      "Test Accuracy for Potato: 0.4514\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 433ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Early Blight       1.00      0.14      0.25        49\n",
      "     Healthy       0.41      1.00      0.58        46\n",
      " Late Blight       0.48      0.24      0.32        49\n",
      "\n",
      "    accuracy                           0.45       144\n",
      "   macro avg       0.63      0.46      0.39       144\n",
      "weighted avg       0.63      0.45      0.38       144\n",
      "\n",
      "\n",
      "Evaluating model for: Tomato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 340ms/step - accuracy: 0.4875 - loss: 2.0101\n",
      "Test Accuracy for Tomato: 0.5321\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 375ms/step\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "        Bacterial Spot       0.87      0.63      0.73        43\n",
      "          Early Blight       1.00      0.06      0.12        48\n",
      "               Healthy       1.00      0.53      0.69        49\n",
      "           Late Blight       0.27      1.00      0.43        47\n",
      "    Septoria Leaf Spot       1.00      0.11      0.20        44\n",
      "Yellow Leaf Curl Virus       1.00      0.84      0.91        49\n",
      "\n",
      "              accuracy                           0.53       280\n",
      "             macro avg       0.86      0.53      0.51       280\n",
      "          weighted avg       0.86      0.53      0.52       280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for plant in test_generators.keys():\n",
    "    print(f\"\\nEvaluating model for: {plant}\")\n",
    "\n",
    "    # Load corresponding model\n",
    "    model = tf.keras.models.load_model(f\"model_{plant}.h5\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(test_generators[plant])\n",
    "    print(f\"Test Accuracy for {plant}: {test_acc:.4f}\")\n",
    "\n",
    "    # Generate classification report\n",
    "    y_true = test_generators[plant].classes\n",
    "    y_pred = np.argmax(model.predict(test_generators[plant]), axis=1)\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=list(test_generators[plant].class_indices.keys())))\n",
    "\n",
    "\n",
    "\n",
    "# # Evaluate the model\n",
    "# test_loss, test_acc = model.evaluate(test_generators[0])\n",
    "# print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d2ef65-d484-48ba-8823-149f876c5ba3",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Confusion matrix</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dcb207ee-3ba9-45cb-89db-df7b2118346b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Loop through all species in test_generators\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, species \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(plant_species):\n\u001b[1;32m---> 12\u001b[0m     test_generator \u001b[38;5;241m=\u001b[39m test_generators[i]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Get true labels and predictions\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m test_generator\u001b[38;5;241m.\u001b[39mclasses\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store overall predictions and true labels\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "all_class_labels = {}\n",
    "\n",
    "# Loop through all species in test_generators\n",
    "for i, species in enumerate(plant_species):\n",
    "    test_generator = test_generators[i]\n",
    "    \n",
    "    # Get true labels and predictions\n",
    "    y_true = test_generator.classes\n",
    "    y_pred = np.argmax(model.predict(test_generator), axis=1)\n",
    "    \n",
    "    # Store results\n",
    "    all_y_true.extend(y_true)\n",
    "    all_y_pred.extend(y_pred)\n",
    "    \n",
    "    # Retrieve class labels for this species\n",
    "    species_labels = list(test_generator.class_indices.keys())\n",
    "    \n",
    "    # Offset class indices for multi-species evaluation\n",
    "    class_offset = len(all_class_labels)\n",
    "    species_class_indices = {k: v + class_offset for k, v in test_generator.class_indices.items()}\n",
    "    all_class_labels.update(species_class_indices)\n",
    "\n",
    "# Reverse dictionary to get ordered class names\n",
    "class_names = [k for k, v in sorted(all_class_labels.items(), key=lambda item: item[1])]\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(all_y_true, all_y_pred, target_names=class_names))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(all_y_true, all_y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix for Multi-Species Plant Disease Detection\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d4926-4929-4efb-b9e4-488d2c7bd93f",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue\">Treatment Recommendation System</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d01e178f-a532-4e7e-9e06-036a62cebeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Treatment for Grape - Leaf Blight: Apply copper-based fungicides. Improve vineyard ventilation.\n"
     ]
    }
   ],
   "source": [
    "# Multi-species treatment recommendations\n",
    "treatment_dict = {\n",
    "    \"Apple\": {\n",
    "        \"Apple Scab\": \"Use fungicides like Captan or Mancozeb. Prune infected leaves.\",\n",
    "        \"Black Rot\": \"Apply copper-based fungicides. Remove infected fruit.\",\n",
    "        \"Cedar Apple Rust\": \"Use fungicides with myclobutanil. Plant resistant varieties.\",\n",
    "        \"Healthy\": \"No treatment needed. Maintain proper watering and nutrients.\"\n",
    "    },\n",
    "    \"Potato\": {\n",
    "        \"Early Blight\": \"Apply chlorothalonil-based fungicides. Rotate crops.\",\n",
    "        \"Late Blight\": \"Use systemic fungicides like Metalaxyl. Remove infected plants.\",\n",
    "        \"Healthy\": \"No treatment needed. Maintain proper soil drainage.\"\n",
    "    },\n",
    "    \"Bell Pepper\": {\n",
    "        \"Bacterial Spot\": \"Use copper-based sprays and avoid overhead watering. Remove infected leaves.\",\n",
    "        \"Healthy\": \"No treatment needed. Ensure proper air circulation.\"\n",
    "    },\n",
    "    \"Cherry\": {\n",
    "        \"Powdery Mildew\": \"Apply sulfur or potassium bicarbonate-based fungicides. Prune affected areas.\",\n",
    "        \"Healthy\": \"No treatment needed. Avoid excessive humidity.\"\n",
    "    },\n",
    "    \"Corn (Maize)\": {\n",
    "        \"Cercospora Leaf Spot\": \"Apply strobilurin or triazole fungicides. Improve field sanitation.\",\n",
    "        \"Common Rust\": \"Use resistant hybrids. Apply fungicides if severe.\",\n",
    "        \"Northern Leaf Blight\": \"Apply fungicides with mancozeb or chlorothalonil. Rotate crops.\",\n",
    "        \"Healthy\": \"No treatment needed. Ensure good soil health.\"\n",
    "    },\n",
    "    \"Grape\": {\n",
    "        \"Black Rot\": \"Apply fungicides like myclobutanil or mancozeb. Remove infected grapes.\",\n",
    "        \"Esca (Black Measles)\": \"Use fungicides containing pyraclostrobin. Prune affected vines.\",\n",
    "        \"Leaf Blight\": \"Apply copper-based fungicides. Improve vineyard ventilation.\",\n",
    "        \"Healthy\": \"No treatment needed. Maintain balanced irrigation.\"\n",
    "    },\n",
    "    \"Tomato\": {\n",
    "        \"Bacterial Spot\": \"Use copper sprays. Avoid handling plants when wet.\",\n",
    "        \"Early Blight\": \"Apply fungicides with chlorothalonil. Remove affected leaves.\",\n",
    "        \"Late Blight\": \"Use systemic fungicides like Metalaxyl. Destroy infected plants.\",\n",
    "        \"Septoria Leaf Spot\": \"Use fungicides with chlorothalonil. Space plants properly for airflow.\",\n",
    "        \"Yellow Leaf Curl Virus\": \"Control whiteflies with insecticidal soap. Use resistant varieties.\",\n",
    "        \"Healthy\": \"No treatment needed. Maintain proper fertilization.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def recommend_treatment(plant, disease):\n",
    "    if plant in treatment_dict and disease in treatment_dict[plant]:\n",
    "        return treatment_dict[plant][disease]\n",
    "    else:\n",
    "        return \"No specific treatment available. Consult an expert.\"\n",
    "\n",
    "# Example usage\n",
    "plant = \"Grape\"\n",
    "disease = \"Leaf Blight\"\n",
    "print(f\"Recommended Treatment for {plant} - {disease}: {recommend_treatment(plant, disease)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6543c24-72ea-4e65-9bd2-79b66a7a42a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d669270-dd02-4dd0-abe0-f0b373ed5ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81c680-6676-4067-8707-15b4ca35cdaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
